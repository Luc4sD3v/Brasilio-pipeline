import requests
import json
import time
import pandas as pd
from pathlib import Path

# === CONFIGURA√á√ÉO ===
BASE_URL = "https://brasil.io/api/v1/dataset/gastos-diretos/gastos/data"
TOKEN = "TOKEN AQUI" 
HEADERS = {"Authorization": f"Token {TOKEN}"}

# === ESTRUTURA DE PASTAS ===
RAW_DIR = Path("dataset/raw")
BRONZE_DIR = Path("dataset/bronze")
RAW_DIR.mkdir(parents=True, exist_ok=True)
BRONZE_DIR.mkdir(parents=True, exist_ok=True)

# === BAIXAR DADOS (at√© a p√°gina 1000) ===
def baixar_dados(limite_paginas=1000):
    url = BASE_URL
    page = 1
    while url and page <= limite_paginas:
        arquivo = RAW_DIR / f"pagina_{page:03}.json"
        if arquivo.exists():
            print(f"‚è© P√°gina {page} j√° existe, pulando...")
            page += 1
            url = f"{BASE_URL}/?page={page}"
            continue

        print(f"üì• Baixando p√°gina {page}...")
        r = requests.get(url, headers=HEADERS)
        if r.status_code == 429:
            print("‚ö†Ô∏è  Muitas requisi√ß√µes ‚Äî esperando 10s...")
            time.sleep(10)
            continue

        r.raise_for_status()
        data = r.json()

        # salva os dados brutos
        with open(arquivo, "w", encoding="utf-8") as f:
            json.dump(data["results"], f, ensure_ascii=False, indent=2)

        url = data["next"]
        page += 1
        time.sleep(2)

    print(f"‚úÖ Download conclu√≠do! ({page-1} p√°ginas processadas)")

# === CONVERTER PARA PARQUET ===
def converter_para_parquet():
    print("üß© Convertendo JSONs para Parquet...")
    dfs = []

    for arquivo in RAW_DIR.glob("*.json"):
        with open(arquivo, "r", encoding="utf-8") as f:
            dados = json.load(f)
        df = pd.DataFrame(dados)
        if "data" in df.columns:
            df["data"] = pd.to_datetime(df["data"], errors="coerce")
            df["ano"] = df["data"].dt.year
            df["mes"] = df["data"].dt.month
        dfs.append(df)

    final = pd.concat(dfs, ignore_index=True)

    for (ano, mes), grupo in final.groupby(["ano", "mes"]):
        pasta = BRONZE_DIR / f"ano={ano}" / f"mes={mes:02}"
        pasta.mkdir(parents=True, exist_ok=True)
        grupo.to_parquet(pasta / "dados.parquet", index=False)

    print("‚úÖ Dados salvos em 'dataset/bronze'")

# === EXECU√á√ÉO AUTOM√ÅTICA ===
if __name__ == "__main__":
    print("üöÄ Iniciando pipeline automatizada (at√© p√°gina 1000)...")
    try:
        baixar_dados(limite_paginas=1000)   
        converter_para_parquet()            
        print("üéâ Pipeline finalizada com sucesso!")
    except Exception as e:
        print(f"‚ùå Erro durante a execu√ß√£o: {e}")
